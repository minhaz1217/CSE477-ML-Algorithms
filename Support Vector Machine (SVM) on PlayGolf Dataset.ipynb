{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # today = (Sunny, Hot, Normal, False) -> output should be YES\n",
    "from sklearn import tree\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "data = [] #to store the data(without the column that contains the class) after reading\n",
    "target = [] # contains the class column\n",
    "featureName = [] # the name of the columns, to use in different situations\n",
    "targetName = [] # the unique values of classlabels\n",
    "className = [] # name of the class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData( ):\n",
    "    \n",
    "    FILENAME = \"playgolf.csv\"\n",
    "    COLUMNSTOIGNORE = [0]  # ignoring the useless columns, these columns will not be read\n",
    "    NULLVALUEINDICATOR = [ -100000, \"?\"]\n",
    "    \n",
    "    global data, target, featureName, targetName, className\n",
    "    tx = []\n",
    "    ty = []\n",
    "    labels = []\n",
    "    columnName = []\n",
    "    with open(FILENAME,encoding=\"utf8\") as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for i, rows in enumerate(csv_reader):\n",
    "#             if(i>5000):\n",
    "#                 break #breaking early just for quick runs\n",
    "            tempData = []\n",
    "            for j,data in enumerate(rows): #reading every column info from a row and ignoring the unnecessary columns\n",
    "                if j not in COLUMNSTOIGNORE:\n",
    "                    tempData.append(data)\n",
    "            nullvalueFound = 0\n",
    "            for j in NULLVALUEINDICATOR:\n",
    "                if(j in tempData):\n",
    "                    nullvalueFound = 1\n",
    "                    break\n",
    "            if(nullvalueFound):\n",
    "                continue\n",
    "            if i>0: #0 th row should be the name row\n",
    "                datas = tempData[:-1]  #last column is the label column so seperating those\n",
    "                label = (tempData[-1:]) #taking just he labels\n",
    "                #print(datas, label)\n",
    "                tx.append(datas)\n",
    "                ty.append(label)\n",
    "            else:\n",
    "                columnName.extend(tempData) #copying array\n",
    "    data = tx\n",
    "    target = ty\n",
    "    mytemp = np.array(target)\n",
    "    #print(np.unique(target).tolist())\n",
    "    targetName = np.unique(target).tolist()\n",
    "    featureName = columnName[:-1]\n",
    "    className = columnName[-1:]\n",
    "    print(className)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Play Golf']\n"
     ]
    }
   ],
   "source": [
    "readData()\n",
    "\n",
    "# print(\"Data In Order: \")\n",
    "# print(\"Target names: \")\n",
    "# print(targetName)\n",
    "# print(\"Features\")\n",
    "# print(featureName)\n",
    "# print(\"Data\")\n",
    "# print(data)\n",
    "# print(\"Targets\")\n",
    "# print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Outlook:Overcast', 'Outlook:Rainy', 'Outlook:Sunny', 'Temperature:Cool', 'Temperature:Hot', 'Temperature:Mild', 'Humidity:High', 'Humidity:Normal', 'Windy:FALSE', 'Windy:TRUE']\n"
     ]
    }
   ],
   "source": [
    "# changing categorical data to one hot\n",
    "'''\n",
    "Training the encoder here on all the data read from the file because \n",
    "if we train the encoder from only the traning dataset then when testing,\n",
    "the encoder thus the model might face unknown valus that don't have any \n",
    "one hot value.\n",
    "Like in testingdata there might be a column named Ghana but there is no\n",
    "value named Ghana in training dataset. so the encoder/model won't know any value for Ghana\n",
    "'''\n",
    "from sklearn import preprocessing\n",
    "\n",
    "dataEncoder = preprocessing.OneHotEncoder()\n",
    "dataEncoder.fit(data)  #training the encoder\n",
    "\n",
    "targetEncoder = preprocessing.OneHotEncoder()\n",
    "targetEncoder.fit(target)\n",
    "\n",
    "\n",
    "#generating combined feature name from the one hot conversion\n",
    "\n",
    "onehotFeatureNames = []\n",
    "for i, val in enumerate(dataEncoder.categories_):\n",
    "#     print(featureName[i])\n",
    "    for j in val:\n",
    "        onehotFeatureNames.append(\"{}:{}\".format(featureName[i],j))\n",
    "print(onehotFeatureNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size:  10 Testing Data Size:  4\n"
     ]
    }
   ],
   "source": [
    "# seperating training data and testing data\n",
    "# for training we use the variables data, target\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import math\n",
    "\n",
    "SPLIT = 70 # means: out of 100, 70 will go to training and 30 will go to testing\n",
    "\n",
    "data, target = shuffle(np.array(data), np.array(target))\n",
    "\n",
    "splitPoint = math.ceil( len(data)*SPLIT / 100.0 )\n",
    "testingData = data[splitPoint:]\n",
    "testingTarget = target[splitPoint:]\n",
    "data = data[:splitPoint]\n",
    "target = target[:splitPoint]\n",
    "\n",
    "print(\"Training Data Size: \", len(data),\"Testing Data Size: \", len(testingData))\n",
    "# print(testingData, testingTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the data using the previously trained encoder\n",
    "oneHotData = dataEncoder.transform(data) #converting the data\n",
    "\n",
    "oneHotTarget = targetEncoder.transform(target)\n",
    "# print(encData.toarray())\n",
    "# print(enc.categories_)\n",
    "# print(eTarget.categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spTarget = []\n",
    "myEncoder = dict()\n",
    "myEncoder[\"Yes\"] = 1\n",
    "myEncoder[\"No\"] = 0\n",
    "myDecoder = dict()\n",
    "myDecoder[0] = \"No\"\n",
    "myDecoder[1] = \"Yes\"\n",
    "for i in target:\n",
    "    spTarget.append( myEncoder[i[0]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 1. 0. 1. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 1. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 1. 1. 0. 1. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 1. 1. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 1. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 1. 0. 1.]]\n",
      "[1 2 3 5 9 0 4 6 7 8]\n",
      "[5 5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#support vector machine\n",
    "\n",
    "from sklearn  import svm\n",
    "SVM = svm.SVC(gamma='scale', decision_function_shape='ovo')\n",
    "SVM.fit(oneHotData.toarray(), spTarget)\n",
    "\n",
    "print(SVM.support_vectors_)\n",
    "print(SVM.support_ )\n",
    "print(SVM.n_support_ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [['Sunny', 'Hot', 'Normal', 'FALSE']]\n",
      "Yes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#today = (Sunny, Hot, Normal, False)\n",
    "trialData = [ ['Sunny', 'Hot', 'Normal', 'FALSE'] ]\n",
    "print(\"Input: \",trialData)\n",
    "trialData = dataEncoder.transform( trialData )  # transforming the given data in to our own one hot\n",
    "prediction = SVM.predict(trialData.toarray())\n",
    "print(myDecoder[prediction[0]])\n",
    "\n",
    "# predictionResult = targetEncoder.inverse_transform(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 25.0%\n"
     ]
    }
   ],
   "source": [
    "# ERROR CALCULATION\n",
    "\n",
    "correctAnswer = 0\n",
    "# print(testingData)\n",
    "testData = dataEncoder.transform( testingData )\n",
    "prediction = SVM.predict(testData.toarray())\n",
    "\n",
    "# predictionResult = targetEncoder.inverse_transform(prediction)\n",
    "\n",
    "# print(\"Testing Data\")\n",
    "# print(testingData)\n",
    "# print(testingData, data)\n",
    "# print(testingTarget, predictionResult)\n",
    "\n",
    "for i,val in enumerate(prediction):\n",
    "    if(val == 1 and target[i] == \"Yes\"):\n",
    "        correctAnswer +=1\n",
    "#     print(val)\n",
    "successRate = correctAnswer / len(testingTarget)\n",
    "print(\"Success rate: {}%\".format(successRate*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
